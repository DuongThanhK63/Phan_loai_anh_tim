{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"PhanLoaiAnhTim.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8YMRTEON1ZJ","executionInfo":{"status":"ok","timestamp":1636126839763,"user_tz":-420,"elapsed":22449,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Y9iRksyQ80o2_GsHZn8iH0yR-y-UgV82_cNVsQ=s64","userId":"17793502573264869330"}},"outputId":"dd7ace86-c13e-4257-a25f-b0f917c46d98"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ZY4k9fVysvDT","executionInfo":{"status":"ok","timestamp":1636126866126,"user_tz":-420,"elapsed":26372,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Y9iRksyQ80o2_GsHZn8iH0yR-y-UgV82_cNVsQ=s64","userId":"17793502573264869330"}}},"source":["import numpy as np\n","import torch\n","from torch import nn\n","import random\n","import torchvision\n","from torchvision import models, transforms\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import json\n","from collections import namedtuple\n","from sklearn.metrics import classification_report\n","import cv2"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKfQyR_U75B_","executionInfo":{"status":"ok","timestamp":1636126866130,"user_tz":-420,"elapsed":26,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Y9iRksyQ80o2_GsHZn8iH0yR-y-UgV82_cNVsQ=s64","userId":"17793502573264869330"}}},"source":["TrainTest = namedtuple('TrainTest', ['train', 'test'])\n","resize = 224\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","#Tao cac class 2C, 3C, 4C\n","def get_classes():\n","  classes = ['2C', '3C', '4C']\n","  return classes\n","\n","#Them Noise vao dataset\n","# class AddGaussianNoise(object):\n","#     def __init__(self, mean=0., std=1.):\n","#         self.std = std\n","#         self.mean = mean\n","        \n","#     def __call__(self, tensor):\n","#         return tensor + torch.randn(tensor.size()) * self.std + self.mean\n","    \n","#     def __repr__(self):\n","#         return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n","\n","#CHuan bi data truoc khi dua vao model\n","def prepare_data():\n","  transform_train = transforms.Compose([\n","      transforms.Resize((resize, resize)),\n","      #transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),  \n","      #transforms.RandomApply(transforms.GaussianBlur(kernel_size=501), p=0.5),                          \n","      transforms.ToTensor()\n","  ])\n","\n","  transform_test = transforms.Compose([\n","    transforms.Resize((resize, resize)),\n","    #transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n","    #transforms.RandomApply(transforms.GaussianBlur(kernel_size=501), p=0.5),\n","    transforms.ToTensor()\n","  ])\n","  #Tao duong dan den data\n","  trainset = torchvision.datasets.ImageFolder(root='./drive/MyDrive/data/DATA_CHAMBER_2021/train', transform=transform_train)\n","  testset = torchvision.datasets.ImageFolder(root='./drive/MyDrive/data/DATA_CHAMBER_2021/test', transform=transform_test)\n","\n","  #In ra so luong anh\n","  print(\"Number of Image in train set:\", len(trainset))\n","  print(\"Number of Image in test set:\", len(testset))\n","  print(\"Classes: \", trainset.class_to_idx)\n","\n","  return TrainTest(train=trainset, test=testset)\n","\n","#Load data dua vao model\n","def prepare_loader(datasets):\n","  trainloader = DataLoader(dataset=datasets.train, batch_size=32, shuffle=True, num_workers=4)\n","  testloader = DataLoader(dataset=datasets.test, batch_size=32, shuffle=False, num_workers=4)\n","  print(\"Num batch in train set: \", len(trainloader))\n","  return TrainTest(train=trainloader, test=testloader)\n","\n","\n","#Ham train model\n","def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n","  model.train()\n","  running_loss = 0.0\n","  reporting_steps = 20\n","  step = 0\n","  for images, labels in loader:\n","    step += 1\n","    images, labels = images.to(device), labels.to(device)\n","    outputs = model(images)\n","    loss = loss_func(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","    if step % reporting_steps == reporting_steps-1:\n","      print(f\"Epoch {epoch} step {step} ave_loss {running_loss/reporting_steps:.4f}\")\n","      running_loss = 0.0\n","#Ham test\n","def test_epoch(epoch, model, loader, device):\n","  ytrue = []\n","  ypred = []\n","  with torch.no_grad():\n","    model.eval()\n","    for images, labels in loader:\n","      images, labels = images.to(device), labels.to(device)\n","      outputs = model(images)\n","      _, predicted = torch.max(outputs, dim=1)\n","\n","      ytrue += list(labels.cpu().numpy())\n","      ypred += list(predicted.cpu().numpy())\n","\n","  return ypred, ytrue\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"uScEYzLP8etf","executionInfo":{"status":"ok","timestamp":1636126866131,"user_tz":-420,"elapsed":27,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0Y9iRksyQ80o2_GsHZn8iH0yR-y-UgV82_cNVsQ=s64","userId":"17793502573264869330"}}},"source":["#Ham khoi tao model\n","def main(MODEL='vgg16'):\n","  classes = get_classes()\n","  datasets = prepare_data()\n","  loaders = prepare_loader(datasets)\n","  device = torch.device(\"cuda:0\")\n","\n","  use_pretrained = False\n","\n","  if MODEL == 'vgg19':\n","    PATH='./vgg19.pth'\n","    model = models.vgg19(pretrained=use_pretrained)\n","    model.classifier[6] = nn.Linear(in_features=4096, out_features=3)\n","  elif MODEL == 'resnet50':\n","    PATH='./resnet18.pth'\n","    model = models.resnet18(pretrained=use_pretrained)\n","    model.classifier[6] = nn.Linear(in_features=512, out_features=3)\n","  else:\n","    PATH='./vgg16.pth'\n","    model = models.vgg16(pretrained=use_pretrained)\n","    model.classifier[6] = nn.Linear(in_features=4096, out_features=3) \n","\n","\n","  model.to(device)\n","  loss_func = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","  for epoch in range(10):\n","    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n","    ypred, ytrue = test_epoch(epoch, model, loaders.test, device)\n","    print(classification_report(ytrue, ypred, target_names=classes))\n","\n","    torch.save(model.state_dict(), PATH)\n","\n","  return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KyziyLy15hXF","outputId":"6f61afb2-80c2-463d-8e81-ce5555aac8e8"},"source":["#Model VGG16\n","model_VGG16 = main(MODEL='vgg16')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Image in train set: 6717\n","Number of Image in test set: 1607\n","Classes:  {'2C': 0, '3C': 1, '4C': 2}\n","Num batch in train set:  210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 step 19 ave_loss 1.0454\n","Epoch 0 step 39 ave_loss 1.0794\n","Epoch 0 step 59 ave_loss 1.0416\n","Epoch 0 step 79 ave_loss 0.7552\n","Epoch 0 step 99 ave_loss 0.5806\n","Epoch 0 step 119 ave_loss 0.5349\n","Epoch 0 step 139 ave_loss 0.4836\n","Epoch 0 step 159 ave_loss 0.2785\n","Epoch 0 step 179 ave_loss 0.2542\n","Epoch 0 step 199 ave_loss 0.1682\n","              precision    recall  f1-score   support\n","\n","          2C       0.89      0.86      0.87       409\n","          3C       0.84      0.94      0.89       367\n","          4C       1.00      0.97      0.98       831\n","\n","    accuracy                           0.93      1607\n","   macro avg       0.91      0.92      0.91      1607\n","weighted avg       0.93      0.93      0.93      1607\n","\n","Epoch 1 step 19 ave_loss 0.1494\n","Epoch 1 step 39 ave_loss 0.1396\n","Epoch 1 step 59 ave_loss 0.1195\n","Epoch 1 step 79 ave_loss 0.1064\n","Epoch 1 step 99 ave_loss 0.1000\n","Epoch 1 step 119 ave_loss 0.1474\n","Epoch 1 step 139 ave_loss 0.0991\n","Epoch 1 step 159 ave_loss 0.8103\n","Epoch 1 step 179 ave_loss 0.4496\n","Epoch 1 step 199 ave_loss 0.2505\n","              precision    recall  f1-score   support\n","\n","          2C       0.85      0.90      0.88       409\n","          3C       0.91      0.85      0.88       367\n","          4C       0.98      0.99      0.99       831\n","\n","    accuracy                           0.93      1607\n","   macro avg       0.92      0.91      0.91      1607\n","weighted avg       0.93      0.93      0.93      1607\n","\n","Epoch 2 step 19 ave_loss 0.0823\n","Epoch 2 step 39 ave_loss 0.1079\n","Epoch 2 step 59 ave_loss 0.0396\n","Epoch 2 step 79 ave_loss 0.0801\n","Epoch 2 step 99 ave_loss 0.0296\n","Epoch 2 step 119 ave_loss 0.0618\n","Epoch 2 step 139 ave_loss 0.0264\n","Epoch 2 step 159 ave_loss 0.0422\n","Epoch 2 step 179 ave_loss 0.0318\n","Epoch 2 step 199 ave_loss 0.0276\n","              precision    recall  f1-score   support\n","\n","          2C       0.88      0.85      0.87       409\n","          3C       0.69      0.98      0.81       367\n","          4C       0.98      0.82      0.89       831\n","\n","    accuracy                           0.86      1607\n","   macro avg       0.85      0.88      0.85      1607\n","weighted avg       0.89      0.86      0.87      1607\n","\n","Epoch 3 step 19 ave_loss 0.0231\n","Epoch 3 step 39 ave_loss 0.0106\n","Epoch 3 step 59 ave_loss 0.0576\n","Epoch 3 step 79 ave_loss 0.0824\n","Epoch 3 step 99 ave_loss 0.0430\n","Epoch 3 step 119 ave_loss 0.0141\n","Epoch 3 step 139 ave_loss 0.0046\n","Epoch 3 step 159 ave_loss 0.0192\n","Epoch 3 step 179 ave_loss 0.0789\n","Epoch 3 step 199 ave_loss 0.0088\n","              precision    recall  f1-score   support\n","\n","          2C       0.95      0.87      0.91       409\n","          3C       0.87      0.97      0.91       367\n","          4C       1.00      0.99      0.99       831\n","\n","    accuracy                           0.95      1607\n","   macro avg       0.94      0.94      0.94      1607\n","weighted avg       0.96      0.95      0.95      1607\n","\n","Epoch 4 step 19 ave_loss 0.0003\n","Epoch 4 step 39 ave_loss 0.0002\n","Epoch 4 step 59 ave_loss 0.0001\n","Epoch 4 step 79 ave_loss 0.0178\n","Epoch 4 step 99 ave_loss 0.0026\n","Epoch 4 step 119 ave_loss 0.0003\n","Epoch 4 step 139 ave_loss 0.0007\n","Epoch 4 step 159 ave_loss 0.0004\n","Epoch 4 step 179 ave_loss 0.0004\n","Epoch 4 step 199 ave_loss 0.0002\n","              precision    recall  f1-score   support\n","\n","          2C       0.80      0.94      0.86       409\n","          3C       0.82      0.97      0.89       367\n","          4C       0.99      0.84      0.91       831\n","\n","    accuracy                           0.89      1607\n","   macro avg       0.87      0.91      0.89      1607\n","weighted avg       0.91      0.89      0.89      1607\n","\n","Epoch 5 step 19 ave_loss 0.0004\n","Epoch 5 step 39 ave_loss 0.0001\n","Epoch 5 step 59 ave_loss 0.0001\n","Epoch 5 step 79 ave_loss 0.0000\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"8a5JI65z_A95"},"source":["#Model VGG19\n","model_VGG19 = main(MODEL='vgg19')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqmsFxPP_BNg"},"source":["#Model Resnet18\n","model_Resnet18 = main(MODEL='resnet18')"],"execution_count":null,"outputs":[]}]}