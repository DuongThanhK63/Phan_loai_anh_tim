{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PhanLoaiAnhTim.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8YMRTEON1ZJ","executionInfo":{"status":"ok","timestamp":1638115377168,"user_tz":-420,"elapsed":22529,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15403613113245512268"}},"outputId":"b78bc670-2dec-4365-abdc-38eeda2a5ab8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ZY4k9fVysvDT","executionInfo":{"status":"ok","timestamp":1638115386166,"user_tz":-420,"elapsed":6669,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15403613113245512268"}}},"source":["import numpy as np\n","import torch\n","from torch import nn\n","import random\n","import torchvision\n","from torchvision import models, transforms\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import json\n","from collections import namedtuple\n","from sklearn.metrics import classification_report\n","import cv2"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKfQyR_U75B_","executionInfo":{"status":"ok","timestamp":1638115453259,"user_tz":-420,"elapsed":323,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15403613113245512268"}}},"source":["TrainTest = namedtuple('TrainTest', ['train', 'test'])\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","\n","def get_classes():\n","  classes = ['2C', '3C', '4C']\n","  return classes\n","\n","def prepare_data():\n","  resize = 224\n","\n","  transform_train = transforms.Compose([\n","      \n","      transforms.Resize((resize, resize)),\n","      #Preprocess: Can bang histogram\n","      #transforms.RandomEqualize(p=0.5),\n","\n","\n","      # Augmentation:Xoay anh, bop meo anh\n","      #transforms.RandAugment(num_ops=3),\n","      #transforms.RandomAffine(degrees=90, translate=None, shear=25),\n","\n","      transforms.ToTensor()\n","      #transforms.Normalize(mean, std)\n","  ])\n","\n","  transform_test = transforms.Compose([\n","    \n","    transforms.Resize((resize, resize)),\n","    \n","    #transforms.RandomEqualize(p=0.2),\n","    #transforms.RandAugment(num_ops=3),\n","    # transforms.RandomAffine(degrees=45, translate=None, shear=15),\n","    \n","    transforms.ToTensor(),\n","    #transforms.Normalize(mean, std)\n","  ])\n","\n","  trainset = torchvision.datasets.ImageFolder(root='./drive/MyDrive/data/DATA_CHAMBER_2021/train', transform=transform_train)\n","  testset = torchvision.datasets.ImageFolder(root='./drive/MyDrive/data/DATA_CHAMBER_2021/test', transform=transform_test)\n","\n","  print(\"Number of Image in train set:\", len(trainset))\n","  print(\"Number of Image in test set:\", len(testset))\n","  print(\"Classes: \", trainset.class_to_idx)\n","\n","  return TrainTest(train=trainset, test=testset)\n","\n","def prepare_loader(datasets):\n","  trainloader = DataLoader(dataset=datasets.train, batch_size=32, shuffle=True, num_workers=4)\n","  testloader = DataLoader(dataset=datasets.test, batch_size=32, shuffle=False, num_workers=4)\n","  print(\"Num batch in train set: \", len(trainloader))\n","  return TrainTest(train=trainloader, test=testloader)\n","\n","def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n","  model.train()\n","  running_loss = 0.0\n","  reporting_steps = 20\n","  step = 0\n","  for images, labels in loader:\n","    step += 1\n","    images, labels = images.to(device), labels.to(device)\n","    outputs = model(images)\n","    loss = loss_func(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","    if step % reporting_steps == reporting_steps-1:\n","      print(f\"Epoch {epoch} step {step} ave_loss {running_loss/reporting_steps:.4f}\")\n","      running_loss = 0.0\n","\n","def test_epoch(epoch, model, loader, device):\n","  ytrue = []\n","  ypred = []\n","  with torch.no_grad():\n","    model.eval()\n","    for images, labels in loader:\n","      images, labels = images.to(device), labels.to(device)\n","      outputs = model(images)\n","      _, predicted = torch.max(outputs, dim=1)\n","\n","      ytrue += list(labels.cpu().numpy())\n","      ypred += list(predicted.cpu().numpy())\n","\n","  return ypred, ytrue\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"uScEYzLP8etf","executionInfo":{"status":"ok","timestamp":1638115464636,"user_tz":-420,"elapsed":324,"user":{"displayName":"Thanh Duong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15403613113245512268"}}},"source":["def main(MODEL='vgg16', type='img'):\n","  classes = get_classes()\n","  datasets = prepare_data()\n","  loaders = prepare_loader(datasets)\n","  device = torch.device(\"cuda:0\")\n","  use_pretrained = False\n","\n","  if MODEL == 'vgg19':\n","    PATH='./vgg19.pth'\n","    model = models.vgg19(pretrained=use_pretrained)\n","    model.classifier[6] = nn.Linear(in_features=4096, out_features=3)\n","  elif MODEL == 'resnet50':\n","    PATH='./resnet50.pth'\n","    model = models.resnet50(pretrained=use_pretrained)\n","    model.fc = nn.Linear(in_features=2048, out_features=3)\n","  else:\n","    PATH='./vgg16.pth'\n","    model = models.vgg16(pretrained=use_pretrained)\n","    model.classifier[6] = nn.Linear(in_features=4096, out_features=3) \n","\n","  model.to(device)\n","  loss_func = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","  for epoch in range(10):\n","    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n","    ypred, ytrue = test_epoch(epoch, model, loaders.test, device)\n","\n","\n","  if type=='img':\n","\n","    print(classification_report(ytrue, ypred, target_names=classes))\n","    torch.save(model.state_dict(), PATH)\n","    return model\n","\n","  elif type=='video':\n","    ytrue = np.array([10])\n","    ypred = np.array([10])\n","    vid = -1\n","    true = 0\n","    count = np.array([0,0,0])\n","    predict = 0\n","    \n","    for i in range (len(datasets.test.imgs)):\n","      if (datasets.test.imgs[i][0].split('C/')[1].split('_')[0] != vid):\n","        if ((count[0] != 0) | (count[1] != 0) | (count[2] != 0)):\n","          max_ = count.max()\n","          for j in range (len(count)):\n","            if (count[j] == max_):\n","              predict = j\n","              break \n","          print('video:',vid, '  true:', true, '  predic:',predict)\n","          ytrue_ = np.append(ytrue_, true)\n","          ypred_ = np.append(ypred_, predict)\n","          count[:] = 0\n","        video = datasets.test.imgs[i][0].split('C/')[1].split('_')[0]\n","        true = ytrue[i] \n","      count[ypred[i]] += 1\n","    print('video:',vid, '  true:', true, '  predic:',predic)\n","    ytrue_ = np.append(ytrue_, true)\n","    ypred_ = np.append(ypred_, predict)\n","    ytrue_ = np.delete(ytrue_, 0)\n","    ypred_ = np.delete(ypred_, 0)\n","\n","    print(classification_report(ytrue_, ypred_, target_names=classes))\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KyziyLy15hXF"},"source":["model_VGG16 = main(MODEL='vgg16')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a5JI65z_A95"},"source":["model_VGG19 = main(MODEL='vgg19')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqmsFxPP_BNg"},"source":["model_Resnet50 = main(MODEL='resnet50')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCMhboxjOqBC"},"source":["video = main(MODEL='vgg16', type='video')"],"execution_count":null,"outputs":[]}]}